{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import shap\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_dataset = pd.read_csv('students_dataset.csv')  \n",
    "students_dataset_1m = pd.read_csv('students_dataset_1m.csv')  \n",
    "\n",
    "df = pd.concat([students_dataset, students_dataset_1m], ignore_index=True)  \n",
    "\n",
    "df[\"disability_status\"] = df[\"disability_status\"].fillna(\"No Disability\")\n",
    "df[\"orphan_status\"] = df[\"orphan_status\"].fillna(\"No Parents\")\n",
    "\n",
    "X = df.drop(columns=[\"dropout_status\"])\n",
    "y = df[\"dropout_status\"]\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['age', 'attendance_rate', 'days_absent_last_semester', 'average_grade',\n",
    "       'household_size', 'behavioral_infractions', 'suspensions',\n",
    "       'distance_to_school', 'transportation_time', 'activities_participation',\n",
    "       'repetitions_in_class', 'previous_dropout_count']\n",
    "categorical_features = ['gender', 'school_category', 'family_income_bracket', 'parental_education_level', 'school_fee_payment_source', 'current_class', 'orphan_status', 'disability_status', 'transportation_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(15, 12))\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    sns.histplot(data=df, x=feature, kde=True, ax=ax)\n",
    "    ax.set_title(f\"Distribution of {feature}\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_xlabel(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    sns.countplot(x=feature, data=df, ax=ax, legend=False, palette=\"Set2\", hue=feature)\n",
    "    ax.set_title(f\"Distribution of {feature}\")\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(15, 12))\n",
    "for i, feature in enumerate(numerical_features):\n",
    "  ax = axes[i // 3, i % 3]\n",
    "  sns.boxplot(x=\"dropout_status\", y=feature, data=df, ax=ax, hue=\"dropout_status\", legend=False, palette=\"Set2\")\n",
    "  ax.set_title(f\"{feature} vs Dropout Status\")\n",
    "  ax.set_ylabel(feature)\n",
    "  ax.set_xlabel(\"Dropout Status\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(drop=\"first\"))\n",
    "])\n",
    "\n",
    "# Combine the transformers in a preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Class distribution after SMOTE:\", pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(C=0.1, solver='saga', random_state=42, max_iter=500)\n",
    "logistic_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "joblib.dump(logistic_model, \"logistic_regression_dropout_model.pkl\")\n",
    "joblib.dump(preprocessor, \"preprocessor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "y_pred_proba = logistic_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Print classification report and ROC-AUC score\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"ROC-AUC Score:\", roc_auc)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"Logistic Regression (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Get encoded column names from the preprocessor\n",
    "encoded_columns = preprocessor.transformers_[1][1].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
    "all_features = numerical_features + list(encoded_columns)\n",
    "\n",
    "# Extract model coefficients and sort by importance\n",
    "model_coef = logistic_model.coef_[0]\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": all_features,\n",
    "    \"Importance\": np.abs(model_coef)\n",
    "})\n",
    "\n",
    "# Calculate percentage importance\n",
    "total_importance = feature_importance[\"Importance\"].sum()\n",
    "feature_importance[\"Importance (%)\"] = (feature_importance[\"Importance\"] / total_importance) * 100\n",
    "\n",
    "feature_importance = feature_importance.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=[\"Feature\", \"Importance (%)\"]),\n",
    "    cells=dict(values=[feature_importance[\"Feature\"], feature_importance[\"Importance (%)\"]])\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Feature Importance Table\",\n",
    "    title_x=0.5,\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Importance (%)\", y=\"Feature\", data=feature_importance.head(15))\n",
    "plt.title(\"Top 15 Features Influencing Dropout Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SHAP explainer\n",
    "explainer = shap.Explainer(logistic_model, shap.maskers.Independent(X_train_resampled))\n",
    "shap_values_test = explainer.shap_values(X_test)\n",
    "\n",
    "# Plot SHAP summary plot for test set\n",
    "shap.summary_plot(shap_values_test, X_test, feature_names=all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(explainer.masker, 'explainer_masker.pkl')\n",
    "joblib.dump(explainer, 'shap_explainer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_explanations(feature):\n",
    "    explanations = {\n",
    "        \"attendance_rate\": \"A lower attendance rate suggests a higher likelihood of dropout.\",\n",
    "        \"behavioral_infractions\": \"More infractions can indicate disengagement or disciplinary issues.\",\n",
    "        \"activities_participation\": \"Lower participation in activities can reflect a lack of engagement.\",\n",
    "        \"repetitions_in_class\": \"More repetitions suggest academic struggles.\",\n",
    "        \"family_income_bracket_Low\": \"Lower family income can be a risk factor.\",\n",
    "        \"suspensions\": \"Higher suspensions may correlate with dropout risk.\",\n",
    "        \"average_grade\": \"Lower grades may indicate academic difficulty.\",\n",
    "        \"school_category_Secondary\": \"In some cases, secondary level students show higher dropout rates.\"\n",
    "    }\n",
    "    return explanations.get(feature, \"No specific explanation available.\")\n",
    "\n",
    "def analyze_student_dropout_advanced(student_data, model, preprocessor, explainer, top_n_features=10):\n",
    "    \"\"\"\n",
    "    Advanced analysis of dropout risk for a given student, displaying the predicted dropout probability,\n",
    "    dropout risk status, top contributing features, and additional visualizations.\n",
    "\n",
    "    Parameters:\n",
    "    - student_data (DataFrame): Data for the student to analyze (1-row DataFrame).\n",
    "    - model: Trained model to make predictions.\n",
    "    - preprocessor: Preprocessing pipeline used for transforming input data.\n",
    "    - explainer: SHAP explainer to interpret the model’s predictions.\n",
    "    - top_n_features (int): Number of top contributing features to display.\n",
    "    \"\"\"\n",
    "    # Transform the student's data using the preprocessing pipeline\n",
    "    student_processed = preprocessor.transform(student_data)\n",
    "\n",
    "    # Predict dropout probability and dropout status\n",
    "    dropout_probability = model.predict_proba(student_processed)[:, 1][0]\n",
    "    dropout_prediction = model.predict(student_processed)[0]\n",
    "\n",
    "    # Extract feature names from the preprocessor after transformation\n",
    "    numerical_features = preprocessor.transformers_[0][2]\n",
    "    categorical_features = preprocessor.transformers_[1][1].get_feature_names_out(preprocessor.transformers_[1][2])\n",
    "    all_features = list(numerical_features) + list(categorical_features)\n",
    "\n",
    "    # Convert processed student data to DataFrame with feature names\n",
    "    student_processed_df = pd.DataFrame(student_processed, columns=all_features)\n",
    "\n",
    "    # Calculate SHAP values for the student data\n",
    "    shap_values = explainer(student_processed_df)\n",
    "\n",
    "    # Convert SHAP values to DataFrame with aligned feature names\n",
    "    shap_values_df = pd.DataFrame(shap_values.values[0], index=all_features, columns=['SHAP Value'])\n",
    "    shap_values_df['Impact'] = shap_values_df['SHAP Value'].abs()  # Add absolute impact for sorting\n",
    "\n",
    "    # Sort SHAP values by absolute impact and get top N features\n",
    "    top_features = shap_values_df.sort_values(by='Impact', ascending=False).head(top_n_features)\n",
    "\n",
    "    # Display results with detailed descriptions\n",
    "    print(\"\\n----- Student Dropout Risk Analysis Report -----\")\n",
    "    print(f\"Predicted Dropout Probability: {dropout_probability * 100:.8f}%\")\n",
    "    print(f\"Predicted Dropout Status: {'High Risk' if dropout_prediction == 1 else 'Low Risk'}\")\n",
    "    print(\"\\nKey Contributing Factors (Positive values increase dropout risk, Negative values decrease it):\")\n",
    "\n",
    "    # Visualization 1: SHAP force plot for this individual prediction (non-interactive)\n",
    "    print(\"\\n--- SHAP Force Plot ---\")\n",
    "    shap.force_plot(explainer.expected_value, shap_values.values[0], feature_names=all_features, matplotlib=True)\n",
    "    plt.show()  # Displaying this plot in a separate container\n",
    "\n",
    "    # Visualization 2: Top Contributing Features Bar Plot using Plotly (Interactive)\n",
    "    top_features_sorted = top_features.sort_values(by=\"SHAP Value\", ascending=True)\n",
    "    fig_bar = px.bar(top_features_sorted, x='SHAP Value', y=top_features_sorted.index,\n",
    "                     labels={'SHAP Value': 'Impact on Prediction', 'index': 'Feature'},\n",
    "                     title=f\"Top {top_n_features} Features Contributing to Dropout Risk\")\n",
    "    fig_bar.show()  # Displaying this plot in a separate container\n",
    "\n",
    "    # Visualization 3: Summary Table of Features, SHAP Values, Impact, Importance, and Explanation\n",
    "    # Prepare data for the summary table\n",
    "    summary_table = top_features.copy()\n",
    "    summary_table['Impact Direction'] = summary_table['SHAP Value'].apply(lambda x: 'Increases' if x > 0 else 'Decreases')\n",
    "    summary_table['Feature Explanation'] = summary_table.index.map(lambda x: feature_explanations(x))\n",
    "\n",
    "    # Calculate the Importance (%) for each feature\n",
    "    total_impact = summary_table['Impact'].sum()\n",
    "    summary_table['Importance (%)'] = (summary_table['Impact'] / total_impact) * 100\n",
    "\n",
    "    # Display an interactive table using Plotly's go.Table method\n",
    "    fig_table = go.Figure(data=[go.Table(\n",
    "        header=dict(values=[\"Feature\", \"SHAP Value\", \"Impact (%)\", \"Impact Direction\", \"Explanation\"]),\n",
    "        cells=dict(values=[summary_table.index, summary_table['SHAP Value'], summary_table['Importance (%)'], summary_table['Impact Direction'], summary_table['Feature Explanation']])\n",
    "    )])\n",
    "\n",
    "    fig_table.update_layout(title=\"Summary Table of Dropout Risk Analysis\")\n",
    "    fig_table.show()\n",
    "\n",
    "    return dropout_probability, dropout_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "loaded_model = joblib.load(\"logistic_regression_dropout_model.pkl\")\n",
    "loaded_preprocessor = joblib.load(\"preprocessor.pkl\")\n",
    "loaded_explainer = joblib.load(\"shap_explainer.pkl\")\n",
    "\n",
    "new_student_data = {\n",
    "    \"age\": [18],\n",
    "    \"gender\": [\"Male\"],\n",
    "    \"disability_status\": [\"No Disability\"],\n",
    "    \"school_category\": [\"Secondary\"],\n",
    "    \"attendance_rate\": [100],\n",
    "    \"days_absent_last_semester\": [0],\n",
    "    \"average_grade\": [85],\n",
    "    \"household_size\": [5],\n",
    "    \"orphan_status\": [\"Double\"],\n",
    "    \"family_income_bracket\": [\"Middle\"],\n",
    "    \"parental_education_level\": [\"Secondary\"],\n",
    "    \"parental_employment_status\": [\"Full-Time\"],\n",
    "    \"school_fee_payment_source\": [\"Parents\"],\n",
    "    \"activities_participation\": [0],\n",
    "    \"behavioral_infractions\": [0],\n",
    "    \"suspensions\": [0],\n",
    "    \"previous_dropout_count\": [0],\n",
    "    \"distance_to_school\": [400],\n",
    "    \"transportation_mean\": [\"Foot\"],\n",
    "    \"transportation_time\": [4],\n",
    "    \"current_class\": [\"S6\"],\n",
    "    \"repetitions_in_class\": [0]\n",
    "}\n",
    "\n",
    "new_student_df = pd.DataFrame(new_student_data)\n",
    "\n",
    "dropout_probability, dropout_prediction = analyze_student_dropout_advanced(new_student_df, loaded_model, loaded_preprocessor, loaded_explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "loaded_model = joblib.load(\"logistic_regression_dropout_model.pkl\")\n",
    "loaded_preprocessor = joblib.load(\"preprocessor.pkl\")\n",
    "loaded_explainer = joblib.load(\"shap_explainer.pkl\")\n",
    "\n",
    "def validate_input(prompt, data_type, min_value=None, max_value=None, choices=None):\n",
    "    \"\"\"\n",
    "    Validates and retrieves user input, ensuring it matches the required data type and constraints.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            value = data_type(input(prompt))\n",
    "            if min_value is not None and value < min_value:\n",
    "                print(f\"Value must be at least {min_value}.\")\n",
    "                continue\n",
    "            if max_value is not None and value > max_value:\n",
    "                print(f\"Value must not exceed {max_value}.\")\n",
    "                continue\n",
    "            if choices and value not in choices:\n",
    "                print(f\"Invalid choice. Available options are: {choices}\")\n",
    "                continue\n",
    "            return value\n",
    "        except ValueError:\n",
    "            print(f\"Invalid input. Please enter a valid {data_type.__name__}.\")\n",
    "\n",
    "\n",
    "def collect_student_data_for_prediction():\n",
    "    \"\"\"\n",
    "    Collects student data interactively from the user to predict dropout probability with validation.\n",
    "\n",
    "    Returns:\n",
    "    - new_student_df (DataFrame): The new student's data in a DataFrame format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary for features and validation rules\n",
    "    feature_info = {\n",
    "        \"age\": {\"type\": int, \"min\": 5, \"max\": 25, \"prompt\": \"Age (5-25): \"},\n",
    "        \"gender\": {\"type\": str, \"choices\": [\"Male\", \"Female\"], \"prompt\": \"Gender (Male/Female): \"},\n",
    "        \"disability_status\": {\"type\": str, \"choices\": [\"No Disability\", \"Physical\", \"Learning\"], \"prompt\": \"Disability Status (No Disability/Physical/Learning): \"},\n",
    "        \"school_category\": {\"type\": str, \"choices\": [\"Primary\", \"Secondary\"], \"prompt\": \"School Category (Primary/Secondary): \"},\n",
    "        \"attendance_rate\": {\"type\": float, \"min\": 0, \"max\": 100, \"prompt\": \"Attendance Rate (0-100): \"},\n",
    "        \"days_absent_last_semester\": {\"type\": int, \"min\": 0, \"max\": 40, \"prompt\": \"Days Absent Last Semester: \"},\n",
    "        \"average_grade\": {\"type\": float, \"min\": 0, \"max\": 100, \"prompt\": \"Average Grade (0-100): \"},\n",
    "        \"household_size\": {\"type\": int, \"min\": 1, \"max\": 15, \"prompt\": \"Household Size (1-15): \"},\n",
    "        \"orphan_status\": {\"type\": str, \"choices\": [\"No Parents\", \"Single\", \"Double\"], \"prompt\": \"Orphan Status (No Parents/Single/Double): \"},\n",
    "        \"family_income_bracket\": {\"type\": str, \"choices\": [\"Low\", \"Middle\", \"High\"], \"prompt\": \"Family Income Bracket (Low/Middle/High): \"},\n",
    "        \"parental_education_level\": {\"type\": str, \"choices\": [\"Not Schooled\", \"Primary\", \"Secondary\", \"Tertiary\"], \"prompt\": \"Parental Education Level (Not Schooled/Primary/Secondary/Tertiary): \"},\n",
    "        \"parental_employment_status\": {\"type\": str, \"choices\": [\"Unemployed\", \"Temporary Work\", \"Full-Time\", \"Part-Time\", \"Self-Employed\"], \"prompt\": \"Parental Employment Status (Unemployed/Temporary Work/Full-Time/Part-Time/Self-Employed): \"},\n",
    "        \"school_fee_payment_source\": {\"type\": str, \"choices\": [\"Parents\", \"Sponsor\", \"Other\"], \"prompt\": \"School Fee Payment Source (Parents/Sponsor/Other): \"},\n",
    "        \"activities_participation\": {\"type\": int, \"min\": 0, \"max\": 5, \"prompt\": \"Activities Participation (0-10): \"},\n",
    "        \"behavioral_infractions\": {\"type\": int, \"min\": 0, \"max\": 10, \"prompt\": \"Behavioral Infractions (0-20): \"},\n",
    "        \"suspensions\": {\"type\": int, \"min\": 0, \"max\": 5, \"prompt\": \"Suspensions (0-10): \"},\n",
    "        \"previous_dropout_count\": {\"type\": int, \"min\": 0, \"max\": 5, \"prompt\": \"Previous Dropout Count (0-10): \"},\n",
    "        \"distance_to_school\": {\"type\": float, \"min\": 0, \"max\": 10000, \"prompt\": \"Distance to School (m): \"},\n",
    "        \"transportation_mean\": {\"type\": str, \"choices\": [\"Foot\", \"Public Transport\", \"Bicycle\", \"Car\"], \"prompt\": \"Transportation Mean (Foot/Public Transport/Bicycle/Car): \"},\n",
    "        \"transportation_time\": {\"type\": int, \"min\": 0, \"max\": 120, \"prompt\": \"Transportation Time (minutes): \"},\n",
    "        \"current_class\": {\"type\": str, \"choices\": [\"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"S1\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\"], \"prompt\": \"Current Class (e.g., P1, P2, ..., S6): \"},\n",
    "        \"repetitions_in_class\": {\"type\": int, \"min\": 0, \"max\": 3, \"prompt\": \"Repetitions in Class (0-3): \"}\n",
    "    }\n",
    "\n",
    "    # Collect data for each feature\n",
    "    student_data = {}\n",
    "    for feature, info in feature_info.items():\n",
    "        print(f\"\\n--- {feature.replace('_', ' ').title()} ---\")\n",
    "        student_data[feature] = validate_input(info[\"prompt\"], info[\"type\"], min_value=info.get(\"min\"), max_value=info.get(\"max\"), choices=info.get(\"choices\"))\n",
    "\n",
    "    # Convert the collected data into a DataFrame\n",
    "    new_student_df = pd.DataFrame([student_data])\n",
    "    return new_student_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_student_df = collect_student_data_for_prediction()\n",
    "analyze_student_dropout_advanced(new_student_df, loaded_model, loaded_preprocessor, explainer=loaded_explainer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
